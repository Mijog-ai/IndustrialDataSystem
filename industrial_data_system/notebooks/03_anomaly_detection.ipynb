{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Testing\n",
    "\n",
    "This notebook tests the anomaly detection functionality using trained autoencoder models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Utilities and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.asc_utils import load_and_process_asc_file\n",
    "from core.db_manager import DatabaseManager\n",
    "\n",
    "# Initialize database manager\n",
    "db_manager = DatabaseManager()\n",
    "\n",
    "print(\"✓ Database manager initialized\")\n",
    "print(f\"  Database path: {db_manager.db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Available Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all trained models in the registry\n",
    "try:\n",
    "    models = db_manager.get_all_models()\n",
    "    \n",
    "    if models:\n",
    "        print(f\"Found {len(models)} trained models:\")\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        for i, model in enumerate(models, 1):\n",
    "            print(f\"\\nModel {i}:\")\n",
    "            print(f\"  ID: {model['model_id']}\")\n",
    "            print(f\"  Name: {model['model_name']}\")\n",
    "            print(f\"  Type: {model['model_type']}\")\n",
    "            print(f\"  Trained: {model['created_at']}\")\n",
    "            print(f\"  Path: {model['model_path']}\")\n",
    "            if model.get('metrics'):\n",
    "                print(f\"  Metrics: {model['metrics']}\")\n",
    "    else:\n",
    "        print(\"No trained models found in the registry.\")\n",
    "        print(\"\\nYou can train a model first using the training notebook or application.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing model registry: {e}\")\n",
    "    print(\"\\nThis notebook requires trained models. Please train a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Data for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to test ASC file\n",
    "test_file = '../Tests/Data/V24-2025__0011_2.ASC'\n",
    "\n",
    "if os.path.exists(test_file):\n",
    "    print(f\"Loading test file: {test_file}\")\n",
    "    df = load_and_process_asc_file(test_file)\n",
    "    print(f\"✓ Loaded DataFrame shape: {df.shape}\")\n",
    "    print(f\"✓ Columns: {df.columns.tolist()[:5]}...\")\n",
    "else:\n",
    "    print(f\"Test file not found: {test_file}\")\n",
    "    print(\"Creating synthetic test data...\")\n",
    "    \n",
    "    # Create synthetic data with some anomalies\n",
    "    n_samples = 5000\n",
    "    t = np.linspace(0, 50, n_samples)\n",
    "    \n",
    "    # Normal operation\n",
    "    pressure = 50 + 5*np.sin(2*np.pi*0.5*t) + np.random.normal(0, 0.5, n_samples)\n",
    "    flow = 100 + 10*np.sin(2*np.pi*0.3*t) + np.random.normal(0, 1, n_samples)\n",
    "    speed = 1500 + 50*np.sin(2*np.pi*0.2*t) + np.random.normal(0, 5, n_samples)\n",
    "    \n",
    "    # Inject anomalies\n",
    "    anomaly_indices = [1000, 2500, 4000]\n",
    "    for idx in anomaly_indices:\n",
    "        pressure[idx:idx+50] += np.random.uniform(15, 25)  # Pressure spike\n",
    "        flow[idx:idx+50] -= np.random.uniform(20, 40)      # Flow drop\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Messzeit[s]': t,\n",
    "        'Pressure [bar]': pressure,\n",
    "        'Flow [L/min]': flow,\n",
    "        'Speed [rpm]': speed,\n",
    "        'Torque [Nm]': 150 + 20*np.sin(2*np.pi*0.4*t) + np.random.normal(0, 2, n_samples)\n",
    "    })\n",
    "    \n",
    "    print(\"✓ Created synthetic test data with injected anomalies\")\n",
    "    print(f\"  Anomalies at indices: {anomaly_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 4 channels\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "channels_to_plot = [col for col in numeric_columns if 'Messzeit' not in col][:4]\n",
    "\n",
    "fig, axes = plt.subplots(len(channels_to_plot), 1, figsize=(14, 3*len(channels_to_plot)))\n",
    "\n",
    "if len(channels_to_plot) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle('Test Data for Anomaly Detection', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, channel in enumerate(channels_to_plot):\n",
    "    axes[i].plot(df.index, df[channel], linewidth=0.8)\n",
    "    axes[i].set_ylabel(channel)\n",
    "    axes[i].set_xlabel('Sample Index')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark known anomaly regions (if using synthetic data)\n",
    "    if 'anomaly_indices' in locals():\n",
    "        for idx in anomaly_indices:\n",
    "            axes[i].axvspan(idx, idx+50, alpha=0.2, color='red', label='Injected Anomaly')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simple Statistical Anomaly Detection\n",
    "\n",
    "Test basic anomaly detection using statistical methods (z-score, IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_zscore(data, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect anomalies using z-score method.\n",
    "    \n",
    "    Args:\n",
    "        data: 1D array of values\n",
    "        threshold: Number of standard deviations from mean\n",
    "    \n",
    "    Returns:\n",
    "        Boolean array indicating anomalies\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    z_scores = np.abs((data - mean) / std)\n",
    "    return z_scores > threshold\n",
    "\n",
    "def detect_anomalies_iqr(data, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Detect anomalies using IQR (Interquartile Range) method.\n",
    "    \n",
    "    Args:\n",
    "        data: 1D array of values\n",
    "        multiplier: IQR multiplier for bounds\n",
    "    \n",
    "    Returns:\n",
    "        Boolean array indicating anomalies\n",
    "    \"\"\"\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - multiplier * iqr\n",
    "    upper_bound = q3 + multiplier * iqr\n",
    "    return (data < lower_bound) | (data > upper_bound)\n",
    "\n",
    "# Test on first numeric column\n",
    "test_channel = channels_to_plot[0]\n",
    "test_data = df[test_channel].values\n",
    "\n",
    "anomalies_zscore = detect_anomalies_zscore(test_data, threshold=3)\n",
    "anomalies_iqr = detect_anomalies_iqr(test_data, multiplier=1.5)\n",
    "\n",
    "print(f\"Anomaly Detection Results for {test_channel}:\")\n",
    "print(f\"  Z-score method (threshold=3): {np.sum(anomalies_zscore)} anomalies ({100*np.sum(anomalies_zscore)/len(test_data):.2f}%)\")\n",
    "print(f\"  IQR method (multiplier=1.5): {np.sum(anomalies_iqr)} anomalies ({100*np.sum(anomalies_iqr)/len(test_data):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Statistical Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Z-score method\n",
    "axes[0].plot(test_data, linewidth=0.8, label='Data', color='steelblue')\n",
    "axes[0].scatter(np.where(anomalies_zscore)[0], test_data[anomalies_zscore], \n",
    "               color='red', s=50, label='Anomalies', zorder=5)\n",
    "axes[0].set_title(f'Z-score Anomaly Detection - {test_channel}')\n",
    "axes[0].set_ylabel(test_channel)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# IQR method\n",
    "axes[1].plot(test_data, linewidth=0.8, label='Data', color='steelblue')\n",
    "axes[1].scatter(np.where(anomalies_iqr)[0], test_data[anomalies_iqr], \n",
    "               color='red', s=50, label='Anomalies', zorder=5)\n",
    "axes[1].set_title(f'IQR Anomaly Detection - {test_channel}')\n",
    "axes[1].set_xlabel('Sample Index')\n",
    "axes[1].set_ylabel(test_channel)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load and Test Trained Model (if available)\n",
    "\n",
    "If you have trained models, you can load and test them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# This section requires a trained model\n",
    "# You can modify the model_path to point to your trained model\n",
    "\n",
    "model_path = None  # Set this to your model path\n",
    "\n",
    "if model_path and os.path.exists(model_path):\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "    \n",
    "    # Prepare data for model prediction\n",
    "    # This will depend on your model's expected input format\n",
    "    # Example:\n",
    "    # features = df[model_features].values\n",
    "    # predictions = model.predict(features)\n",
    "    # reconstruction_error = np.mean((features - predictions) ** 2, axis=1)\n",
    "    \n",
    "else:\n",
    "    print(\"No trained model specified.\")\n",
    "    print(\"\\nTo use a trained model:\")\n",
    "    print(\"1. Train a model using the training application\")\n",
    "    print(\"2. Set model_path to the path of your trained model file\")\n",
    "    print(\"3. Rerun this cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sliding Window Anomaly Detection\n",
    "\n",
    "Test anomaly detection using sliding windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_anomaly(data, window_size=100, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect anomalies using sliding window statistics.\n",
    "    \n",
    "    Args:\n",
    "        data: 1D array of values\n",
    "        window_size: Size of the sliding window\n",
    "        threshold: Z-score threshold\n",
    "    \n",
    "    Returns:\n",
    "        Array of anomaly scores for each point\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    anomaly_scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(window_size, n):\n",
    "        window = data[i-window_size:i]\n",
    "        mean = np.mean(window)\n",
    "        std = np.std(window)\n",
    "        \n",
    "        if std > 0:\n",
    "            anomaly_scores[i] = np.abs((data[i] - mean) / std)\n",
    "    \n",
    "    return anomaly_scores\n",
    "\n",
    "# Test sliding window detection\n",
    "window_sizes = [50, 100, 200]\n",
    "fig, axes = plt.subplots(len(window_sizes), 1, figsize=(14, 4*len(window_sizes)))\n",
    "\n",
    "if len(window_sizes) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, window_size in enumerate(window_sizes):\n",
    "    scores = sliding_window_anomaly(test_data, window_size=window_size, threshold=3)\n",
    "    anomalies = scores > 3\n",
    "    \n",
    "    axes[i].plot(test_data, linewidth=0.8, label='Data', alpha=0.7)\n",
    "    axes[i].scatter(np.where(anomalies)[0], test_data[anomalies], \n",
    "                   color='red', s=30, label='Anomalies', zorder=5)\n",
    "    axes[i].set_title(f'Sliding Window Anomaly Detection (window={window_size})')\n",
    "    axes[i].set_ylabel(test_channel)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    print(f\"Window size {window_size}: {np.sum(anomalies)} anomalies detected\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANOMALY DETECTION TEST SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"✓ Data loaded: {df.shape[0]} samples, {df.shape[1]} channels\")\n",
    "print(f\"✓ Test channel: {test_channel}\")\n",
    "print(f\"\\nStatistical Methods:\")\n",
    "print(f\"  - Z-score: {np.sum(anomalies_zscore)} anomalies\")\n",
    "print(f\"  - IQR: {np.sum(anomalies_iqr)} anomalies\")\n",
    "print(f\"\\nSliding Window Methods:\")\n",
    "for window_size in window_sizes:\n",
    "    scores = sliding_window_anomaly(test_data, window_size=window_size)\n",
    "    n_anomalies = np.sum(scores > 3)\n",
    "    print(f\"  - Window {window_size}: {n_anomalies} anomalies\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
